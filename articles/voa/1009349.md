<!--1737770343000-->
[俄罗斯深伪视频锁定包括未成年人在内的乌克兰难民](https://www.voachinese.com/a/russian-deepfake-videos-target-ukrainian-refugees-including-teen-20250124/7949789.html)
------

<div><i>Sat, 25 Jan 2025 01:41:02 GMT</i></div><img src="https://images.weserv.nl?url=gdb.voanews.com/01000000-0aff-0242-f7f9-08dc8014fd79_r1_s.png" width="100%"><div><small style="color: #999;">针对美国选举的深伪视频截图。专家们将其起源追溯到俄罗斯。</small></div><p>美国之音(VOA)俄罗斯语和乌克兰语组最近调查的在线视频显示，人工智能(AI)很可能被用来制作针对乌克兰难民的挑衅式深度伪造视频。<br /><br />在其中的一个例子中，一段视频似乎是关于一名十几岁的乌克兰难民少女在美国私立学校学习经历的电视新闻报道。<br /><br />但随后视频切换到拥挤的学校走廊和一包包可卡因的画面，而画外音听起来像是这名女孩称，美国公立学校很危险，并引发了对非洲裔美国人的冒犯性的刻板印象。<br /><br />“我知道(私立学校)费用相当昂贵，”她说。“但如果让我的家人为我的安全买单，那不公平。让美国人来买单吧。”<br /><br />这些说法完全是捏造的。只有第一部分--少女的镜头--是真实的。<br /><br />这段冒犯性的画外音很可能是使用人工智能逼真地复制了她的声音，从而产生了所谓的深度伪造。<br /><br />这似乎是俄罗斯网络信息行动“俄罗斯套娃”(Matryoshka)的一部分，目前针对的是乌克兰难民。<br /><br />美国之音发现，该行动推出了两个深度伪造视频，旨在让乌克兰难民看起来贪婪和忘恩负义，同时还传播深度伪造视频，似乎显示权威的西方记者声称乌克兰--而不是俄罗斯--是传播谎言的国家。<br /><br />据研究俄罗斯信息行动的X账户Antibot4Navalny称，这些视频反映了俄罗斯网络造假运动的最新策略，该账户已被西方主要新闻媒体广泛引用。<br /><br />俄罗斯有意针对难民--包括一名青少年--表明克里姆林宫正不遗余力地试图破坏西方对乌克兰的支持，而克里姆林宫则经常否认涉足造假。<br /><br /><strong>针对受害者</strong><br /><br />第二个针对乌克兰难民的视频以新闻报道中的真实镜头开始，其中一名乌克兰妇女对丹麦向难民提供的衣物捐赠和支持表示感谢。<br /><br />然后视频切换到通用的画面和可能的深度伪造，因为该女子的声音开始抱怨乌克兰难民被迫住在小公寓里并穿二手衣服。<br /><br />美国之音不会分享这两个视频，以保护深度伪造中描绘的难民的身份，但这两段视频都使用了从知名国际媒体窃取的镜头。<br /><br />Antibot4Navalny告诉美国之音，这种手法--在复制他们声音的同时改变具体人物的陈述--对“俄罗斯套娃”来说是新招术。<br /><br />“在过去几周里，几乎所有剪辑都是按照这个方案制作的，”这个研究小组写道。<br /><br />但专家表示，伪造真实媒体报道并针对难民的潜在策略，毫不新鲜。<br /><br />大西洋理事会(Atlantic Council)数字取证研究实验室的常驻研究员罗曼·奥萨丘克(Roman Osadchuk)举例说，在俄罗斯于2022年4月对乌克兰克拉马托尔斯克火车站发动致命导弹袭击后，克里姆林宫制作了一份虚假的英国广播公司(BBC)的新闻报道，指责乌克兰人发动了这次袭击。<br /><br />他指出，在同一时期，俄罗斯还在摩尔多瓦散布虚假信息，旨在让当地民众反对乌克兰难民。<br /><br />“不幸的是，难民是俄罗斯虚假宣传活动非常喜欢针对的目标，他们不仅攻击东道国社区......也是攻击乌克兰，”奥萨丘克告诉美国之音。</p><p>他补充说，当此类虚假宣传行动针对乌克兰受众时，其目标往往是挑拨离间，分化离开乌克兰的人和留在国内的人。<br /><br />然而，假冒记者的深度伪造似乎旨在以不同的方式影响公众舆论。例如，一段据称包含贝灵猫(Bellingcat)创始人艾略特·希金斯(Eliot Higgins)音频的视频声称，乌克兰入侵俄罗斯库尔斯克地区只是虚张声势。<br /><br />“全世界都在关注乌克兰的死亡痉挛，” 希金斯似乎在说。“没有什么可讨论的了。”<br /><br />在另一段视频中，英国广播公司核查团队(BBC Verify)的资深记者沙延·萨达里扎德(Shayan Sardarizadeh)似乎在说，“乌克兰制造假新闻，以便事实核查机构指责俄罗斯”，他随后将此描述为“全球骗局”的一部分。<br /><br />事实上，这两个视频似乎都是深度伪造的，其制作方式与针对难民的视频相同。<br /><br />希金斯告诉美国之音，模仿他自己声音的整个音频似乎都是深度伪造的。他暗示，该视频的目的是吸引事实核查人员，并让他们意外地增加其点击率。<br /><br />“我认为这更多的是为了提高他们的统计数据，以便(造假者)可以继续从俄罗斯政府捞钱来继续这样做，”他通过电子邮件告诉美国之音。<br /><br />截至本文发表，萨达里扎德没有回应置评请求。<br /><br /><strong>虚假视频，真实危害</strong><br /><br />过去几年，人工智能的快速扩张引起了人们对深伪视频和人工智能图像问题的日益关注，尤其是当这些技术被用于制作非自愿的、露骨的色情图像时。<br /><br />研究人员估计，网上超过90%的深度伪造视频都含有露骨色情内容。这些视频既被用来攻击普通女性，也被用来攻击未成年女孩和名人。<br /><br />深伪也被用来针对政界人士和公职候选人。然而，目前尚不清楚它们是否真的影响了舆论或选举结果。<br /><br />微软(Microsoft)威胁分析中心(Threat Analysis Center)的研究人员发现，世界领导人的“完全人工合成”视频往往不令人信服，而且很容易被揭穿。但他们也得出结论，深度伪造音频通常更有效。<br /><br />“俄罗斯套娃”(主要使用深度伪造音频)发布的四个视频表明，深伪的危险不仅限于露骨的图像或对政界人士的模仿。如果你的图像可以在网上找到，你就没有多少办法可以完全保护自己。<br /><br />如今，“公开分享任何信息，包括你的声音、外表或照片”，总是存在风险，奥萨丘克说。<br /><br />对个人的伤害可能很严重。<br /><br />专门从事技术政策和民权事务的律师贝尔·托雷克(Belle Torek)表示，未经同意使用肖像的人经常会感到被侵犯、羞辱、无助和恐惧。<br /><br />“他们倾向于报告他们感觉自己的信任被侵犯。知道他们的形象被操纵来传播谎言或仇恨会加剧现有的创伤，”她说。“在这种情况下，我认为这些影响对这些(难民)社区来说将会放大，而他们已经在忍受流离失所和暴力了。”<br /><br /><strong>深伪多么有效？</strong><br /><br />虽然不难理解深度伪造的潜在危害，但评估其更广泛的影响范围和影响更具挑战性。<br /><br />X上的一篇以难民的虚假视频为特色的帖子获得了超过5.5万次观看。据战略对话研究所(Institute for Strategic Dialogue)高级分析师奥尔加·托卡里克(Olga Tokariuk)称，这表明传播范围很广。<br /><br />“这还不算蹿红的内容，但也不再是不起眼的内容了，”她说。<br /><br />另一方面，Antibot4Navalny认为，俄罗斯的虚假信息参与者主要使用其他受控账户来放大X帖子，很少有真正的人看到它们。<br /><br />但即使有大量真人确实观看了深伪视频，也并不一定意味着这些视频实现了克里姆林宫的目标。<br /><br />“要100%地证明这些虚假信息活动对政治的影响，总是很困难的，” 托卡里克说。</p>
