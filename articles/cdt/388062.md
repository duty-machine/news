<!--1608012731000-->
[人物｜困于人脸识别](https://chinadigitaltimes.net/chinese/2020/12/%e4%ba%ba%e7%89%a9%ef%bd%9c%e5%9b%b0%e4%ba%8e%e4%ba%ba%e8%84%b8%e8%af%86%e5%88%ab/)
------

<p><img src="https://chinadigitaltimes.net/chinese/files/2020/12/post-660513-5fd853267157d." alt="图片" class="aligncenter" width="500"></p><p>在现代社会，一个人的匿名性相当重要。你并不想所有举动都被毫无遗漏地永久记载下来，曝光在每一个人的面前。匿名性是现代社会运作的基础。</p><p><strong>文｜</strong>汤禹成</p><p><strong>编辑｜</strong>槐杨</p><p><strong>图片｜</strong>cfp</p><p><strong>进入日常缝隙处</strong></p><p>今年3月，劳东燕发现，小区每单元的电梯里都贴上了通知，要求业主下载一个APP，录入人脸信息，用于门禁升级。劳东燕是清华大学的法学教授，从去年起，她发现人脸识别被运用在越来越多的场景——分类安检的地铁口，AI换脸的手机游戏，就连法学院的自动咖啡机也有了人脸支付这一选项。</p><p>看到通知的那一刻，她意识到，这项技术，已经从高铁站、飞机场这些公共领域，进入工作地点、生活住所，试图渗入人们日常生活的每一个缝隙——这在后来被一步步证实。借着疫情防控和智慧小区建设的趋势，人脸识别系统很快在城市的多个小区迅速推开。2017年，北京住房和城乡建设委员会启动智慧小区建设时，早已提出这样的畅想：「您能想象未来小区没有门禁卡就能开门，停车共享车位、分时租赁，居家老人实现机器人陪护的生活吗？」</p><p>但是，崭新科技所叙述的振奋人心的故事，同样也存在被科技打破的风险。一位麻省理工学院计算机科学专业的博士告诉我，通过人像收集与机器学习，黑客不仅能将你的脸替换至色情视频，也可以用「对抗攻击」（Adversarial attack）技术迷惑机器学习模型，代替你进入高铁站，你工作的单位，甚至是你的家。</p><p>生物数据，包括指纹，一直存在泄露和被伪造的风险，但随着机器学习技术的发展以及人脸识别大规模应用，人脸信息变得更为敏感。理论上来说，「你在社交媒体上公开的所有照片，都可能成为被利用的生物信息」。</p><p>另一些事实证明，储存和维护数据的系统并没有那么强大。2018年7月，浙江绍兴一名叫张富的大专毕业生，利用非法购买的公民个人身份信息，将相关公民的照片制成3D头像，通过支付宝人脸识别认证。在他被查获的电脑里，警方发现了2000万条公民个人信息。2019年，18岁、初中文化的田某，通过抓取、拦截、保存银行系统下发的人脸识别身份信息数据包，在一个手机银行APP内使用虚假身份信息成功注册了账户。</p><p>劳东燕知道这项技术的隐忧。她将收集到的材料发在了一个两百多人的小区微信群中。一位关心此事的居民，又将她拉进了接近500人的小区业主群。在那里，她发的材料获得更多共鸣，许多业主表达了对风险的担忧。此前，业主们主要的不满是：「干嘛要收集房产证信息？」</p><p><img src="https://chinadigitaltimes.net/chinese/files/2020/12/post-660513-5fd8532880944." alt="图片" class="aligncenter" width="500"></p><p><em>杭州居民戴口罩刷脸进小区，该系统在居民戴着口罩的情况下，也可以精准识别</em></p><p><strong>「挣扎」</strong></p><p>3月15日，劳东燕写好详细的法律意见，指出小区的收集行为与现行法律框架相违背。一式两份，寄给物业和居委会。邮寄是她特意选择的方式——通过快递寄送，对方一旦签收，就能代表送达。</p><p>几天后的一个傍晚，街道办主任给她打电话，邀请她一起讨论。在场的还有居委会和物业的工作人员。劳东燕察觉到，街道办的工作人员更关注法律风险。当她提醒「单方通知不代表同意，不经同意就获取，在刑法上就会界定为非法获取」，他们问，应该如何规避这样的风险。</p><p>而劳东燕最担心的是数据风险。她无法想象「物业有何动力维护和保护这个数据系统」。她问：「数据由谁保管？怎么保护？」</p><p>对方给出三种方案：存放在物业的局域网，交给便民服务中心，公安部门也可以保管。那时，已经有居民录入人脸信息，但存放方案始终未有定论。这些方案本身也反映了国内个人信息保护的现状——在使用和管理数据上，公权力和商业机构间并没有严格界限。这些加剧了劳东燕的担忧。</p><p>街道办主任试图劝服劳东燕。先用「便捷」。在他们的叙述中，因为每个单元的门禁都坏了，街道帮大家免费更新人脸门禁系统，相当于给小区居民提供福利。「你看使用多便利呀，一刷脸就行了。」劳东燕答，「刷脸省的几秒钟，对我没有多大的价值。」</p><p>在场的业委会主任则以「房价」为谈判筹码：「我们小区管理好了，房价也会跟着上去」，这句话令劳东燕印象深刻。</p><p>再是「安全」。「这样的技术可以更好地打击违法犯罪分子」，对方说。</p><p>「如果监听全国所有人的手机通信，可以发现更多犯罪分子，我们会允许监听监控所有人的手机吗？打击犯罪只是社会的一个目标，甚至不是基本目标。」</p><p>讨论到最后，街道办给出3种可替代方案，不愿录入人脸的居民，也能依靠刷门禁卡、身份证登记或使用手机APP回到自己的家。</p><p>9月23日午后，在一场主题为「小区门禁能否人脸识别」的专题研讨会上，劳东燕简单地讲述了这段经历。在场另一位嘉宾说她是「为了权利而斗争」。劳东燕笑了笑，摆手解释：「没有，我也只是稍微挣扎了一下」。</p><p><img src="https://chinadigitaltimes.net/chinese/files/2020/12/post-660513-5fd8532a774f5." alt="图片" class="aligncenter" width="500"></p><p><em>人脸识别已经进入到我们生活的方方面面</em> </p><p><strong>「坏了的门牙」</strong></p><p>有人试图更剧烈地「挣扎」一下。2019年4月，浙江理工大学特聘副教授郭兵，在杭州野生动物世界办了一张价值千元的年卡，凭借这张卡和指纹，郭兵和家人可以一年不限次数畅游。但10月17日，他收到一条野生动物世界发来的短信，「即日起，未注册人脸识别的用户将无法正常入园。」</p><p>郭兵以违背《消费者权益保护法》为由，将杭州野生动物世界告上了法庭。将近1年后，他和我叙述当时的初衷：除了感到权益受到侵害，作为一个教授法律的大学老师，他更希望推动一个具有公益性质的诉讼——在个人信息失控的当下，促成相关制度的完善。</p><p>郭兵说，他办年卡时，并不知道要录指纹，交完钱去拿卡时才被要求，他知道生物信息的敏感性，出示身份证就可以证明身份，为什么还要录指纹？对方告诉他，入园处只有指纹这一种方式。孩子在哭，妻子在催，他妥协了。但打官司时，他发现动物园向法院提交的证据中包括自己的一张照片——当时没有人告诉他这张照片的用途，他以为是贴在年卡上，但动物园的解释是「游客当时同意拍照，就视为同意园方收集面部信息用于人脸识别」。在郭兵的叙述里，面对更为强势的商业机构，个体的意愿已经在浑然不知中被扭曲和剥夺。</p><p>案子在今年6月开庭，按正常流程，法院本应在9月给出判决。但承办人告诉郭兵，法院认为属于「疑难复杂案件」，案子的审限到期前经法院院长批准又延了6个月。</p><p>11月20日，杭州富阳法院做出一审判决，责令野生动物世界赔偿由于单方变更合同造成的经济损失、删除郭兵个人信息，同时，驳回了郭兵提出的「确认野生动物世界店堂告示、短信通知中相关内容无效」等其他诉讼请求，认为「野生动物世界以店堂告示的形式告知购卡人需提供部分个人信息，未对消费者作出不公平、不合理的其他规定，客户的消费知情权和对个人信息的自主决定权未受到侵害……野生动物世界在经营活动中使用指纹识别、人脸识别等生物识别技术，其行为本身并未违反前述法律规定的原则要求。」</p><p>郭兵对这个结果并不满意，他在朋友圈里无奈地说：「不少朋友说算是胜诉了，我自己则表示不服。」</p><p>即便判决结果不尽人意，郭兵的诉讼案和去年10月劳东燕发表的一篇讲述人脸识别隐忧的专栏文章一起，已然成为引发人们关于人脸识别技术反思的「蝴蝶翅膀」。今年9月初，赵逢（化名）决定也挣扎一下。他住了7年的小区开始实行人脸识别门禁系统，在居委会阿姨的催促下，他在小区门口录入了人脸信息，此后，他陷入一种担忧，人脸信息是否有泄漏的风险？</p><p>他去找过居委会，居委会负责人同样以「便利」与「安全」来说服这个「大惊小怪」的年轻人。又过了几天，他在网上看到了劳东燕在那场研讨会上的分享——他意识到，「当没有完善的法律保障时，个人信息极有可能被滥用」。</p><p>他给12345投诉信箱写信，介绍前因后果，质疑合法性，继而要求删除他的人脸与个人信息。进展比预料的更顺利，在街道办的协调下，他在9月底来到物业，看着物业工作人员对着他的人脸信息按下了删除键。</p><p>「一种未知的恐惧」，赵逢说。为了更精确地解释这种感受，他举了一个例子：他曾修整过门牙，结果门牙坏了，这件事的具体风险是——假如有天吃一个苹果，牙齿可能会被磕掉。这种具体的风险是有应对方法的，磕掉了就再去做一颗，「但它会导致一种不自由的状态，就是你没办法随心所欲地吃苹果了」。</p><p>走出物业时，他松了口气。他知道他仍处在一个巨大的、关乎个人信息的系统里，但他获得了一种暂时的安全感：「我要是不挣扎，我就没有答案。我就永远要背上那个问号。」</p><p>而在杭州，开庭结束的当天下午，郭兵又驱车到距离法院并不很远的杭州野生动物世界。检票口的工作人员不认识他，他询问指纹年卡会员的入园方式，对方的回答依然不留余地：「只能刷脸入园。」</p><p><img src="https://chinadigitaltimes.net/chinese/files/2020/12/post-660513-5fd8532cb0e1c." alt="图片" class="aligncenter" width="500"></p><p><em>山东某景区，工作人员正在引导游客刷脸入园</em></p><p>不久前，我和劳东燕教授在清华园东南边的书店，就「人脸识别」展开了一次谈话。我们聊到技术的风险与反噬性，聊到有待完善的法律框架，也聊到身处庞大系统中的普通个体可以如何「挣扎」。她反复表达了自己的担忧，人脸识别技术如若不加以规制，将会影响整个社会的走向。那次访谈后，《个人信息保护法（草案）》问世，天津立法禁止采集人脸识别信息，南京要求售楼处拆除人脸识别系统，细微的变化正在发生。《人物》又与劳东燕教授谈论了这些新的消息。以下为两次对话的内容：</p><p><strong>《人物》：你是怎么关注到人脸识别技术带来的风险的？</strong></p><p><strong>劳东燕：</strong>由于人脸识别的底层技术在2018年有很大突破，去年下半年开始，我注意到人脸识别商业化的推广在中国「遍地开花」，连我们学院的咖啡机都通过少付1元钱而引诱人们使用人脸识别支付。我一直在研究「风险社会」，在风险社会中，预防风险的措施本身可能会带来新的风险。关注人脸识别时，我不仅关注机器学习、数据泄露可能导致的财产与人身威胁，还会关注相关部门运用这种技术所带来的社会风险。 </p><p><strong>《人物》：在人脸识别这项技术的使用和接受度上，疫情前后有不一样的感受吗？</strong></p><p><strong>劳东燕：</strong>去年下半年我还挺欣慰的，对于个人信息保护，整个主流舆论有所转向，一些主流媒体也开始报道「人脸识别」潜含的风险，不像以前那样漠不关心。后来疫情来临，我们需要通过人脸识别认证健康码，交出我们的轨迹，让渡我们的个人信息。为了保持正常的生活，不得不这么做。疫情对整个社会走向的影响太大了，更多人开始接受这样的状态。 </p><p><strong>《人物》：你认为，人脸识别技术带来的风险主要有哪些？</strong></p><p><strong>劳东燕：</strong>从最浅的层面说，如果你的生物信息被别人获取，别人就可能用你的脸结合你的身份证信息，去登陆你的银行账户，转移账户中的钱，进入你本该进入的单位、小区，或者恶心你一下，把你的脸换到淫秽视频里。这些风险，是和居民的日常生活最相关的。而且人脸、指纹这样的生物信息，一旦泄露，无法改变，也无法获得救济，你可能永远暴露在这样的风险下。</p><p>和指纹相比，人脸信息的风险更突出，因为它具有非接触性。如果要获取我的指纹，我是知道的，而且指纹泄露后，别人也不知道这个指纹是我的；但人脸泄露后，马上就能知道是我，其他人都可以迅速锁定我。清华新闻学院的一位教授，在接受《中国新闻周刊》的采访时曾提到，我们每天有500次被摄像头照到的机会。其中有多少摄像头具有人脸识别的功能，或者收集提取了我们的人脸数据，我们根本不知道。</p><p><img src="https://chinadigitaltimes.net/chinese/files/2020/12/post-660513-5fd8532e94438." alt="图片" class="aligncenter" width="500"></p><p><em>随处可见的摄像头</em></p><p><strong>《人物》：为什么生物信息一旦泄露，就无法救济呢？</strong></p><p><strong>劳东燕：</strong>假设你的人脸信息泄露了，你想通过民法途径救济，民法讲究「谁主张，谁举证」，现在这么多地方在收集，你不知道是谁收集的，不知道是从何处泄露的，也不知道泄露或滥用的人是谁。你举证不了。</p><p>想走行政法或刑法保护的途径，也不那么容易。只有大规模的数据泄露，才可能推动公安机关启动侦查活动。但是，即便公安机关把犯罪分子抓住了，也只是把他关在监狱。你的信息泄露了就是泄露了，他已经卖给下家，下家可能又卖给另一下家，已然失控，你没办法恢复原状。</p><p><strong>《人物》：所以人脸识别应用「遍地开花」的现象，本身就潜含巨大的风险？</strong></p><p><strong>劳东燕：</strong>我们眼下管控风险的能力，跟技术制造风险的能力相比，完全不配套，这是普遍问题。无论是法律手段还是政治手段或其他社会治理手段，进化上都是很慢的，跟不上技术的迭代以及商业化的快速推进。</p><p>眼下，好像任何一个机构，都可以推广人脸识别。其中最有动力的是科技公司，它们可以卖设备，接下来还可以收取后续维护的费用。人脸识别的推广会带动这个产业的发展。但这个产业的发展跟全社会利益相比微乎其微。一些部门也有动力，因为这样更便于维护治安，对流动人口的管理也会更容易，但这样可能损害了同样重要甚至更为重要的社会价值。小区物业也在推广，但它根本没有动力和财力升级系统、维护数据安全。所以「遍地开花」是最可怕的——安全问题有短板效应，互联网时代的特点是，问题不会出在安防水平最高的地方，而是出在水平最低能力最差的地方。多组织、多中心地收集信息，比单一中心的收集，风险要更大。</p><p><strong>《人物》：除了刚才谈到的那些，还有什么更长远、隐蔽的风险吗？</strong></p><p><strong>劳东燕</strong>：一旦手机上、电脑中，还有这些遍布在各个角落的摄像头所获取的数据全被打通，人就变成透明人了。数据的拥有者，可以知道你的一切，你每天回家的路径，你开什么车，跟哪些人交往，你的购物喜好，你的网页浏览记录，你的立场，这些信息串起来后，他们可能比你更了解你自己。在这样的情况下，一切将变得不可控，甚至会影响现代社会的基本制度。国外已出现商业公司通过分析个人数据来影响选举的新闻。技术可能会把社会带向一个跟我们追求的目标彻底背道而驰的方向。</p><p><strong>《人物》：目前的法律足以保护我们在生物信息上的权利吗？未来，关于个人信息保护的法律框架，会往什么方向发展？</strong></p><p><strong>劳东燕：</strong>目前对个人信息的保护仍主要建立在对传统社会的想象上，法律上将数据当作与财物一样的东西。对财物保护来讲，最重要的是占有，如果你不告而取，我就要惩罚你。但实际上，数据与财物不一样，数据具有共享性，使用时不具有排他性。在数据的问题上，不告而取地收集当然有其危害，但是即便经作为数据主体的当事方同意，接下来难道就可以随意使用他相应的个人数据吗？肯定不能。</p><p>眼下我们法学界基本达成共识，以同意机制作为核心的保护机制是有问题的。未来，法律上可能会将保护义务更多放在信息的收集者和控制者身上。信息的控制者要承担信息保护方面的任务，而个体需要对自己的数据掌握一定的控制权。比如，你同意别人收集了你的个人数据之后，接下来后续种种，他应该告诉你，接下来会怎么使用，作为提供数据的个体也应该有权提出删除。其次，在风险的分配问题上，由于数据收集者和处理者的收集和使用行为制造的风险，谁制造风险，谁就要对风险造成的结果来负责；同时，谁从中获取最大的利益，谁也就应该负责其中主要的风险。</p><p>最近刚公布的《个人信息保护法（草案）》在落实知情-同意的机制上有了比较切实的举措，10月1日生效的新版《个人信息安全规范》对信息收集者也提出了更具体的要求，这些都表明好的改变正在发生。我认为，我也希望，整个法律能够强化对个体权益的保护。至少从我的观察来看，我们刑法中对于秩序利益、安全利益的关注，远远超过对于个体权益的保护。</p><p><strong>《人物》：郭兵和杭州野生动物世界的案子在11月20日宣判，你对这个判决结果怎么看？</strong></p><p><strong>劳东燕：</strong>总的来说，我认为这样的判决对于推动个人信息保护的意义很有限，它不会成为一个标志性的判决。判决书当中认为动物园可以这么做，我认为这是不合理的，它理应给消费者提供其他选择。动物园收照片的时候，没有告知这张照片要用于人脸识别，这明显是侵权，动物园理应承担相应的后果。像这些问题，判决书中都完全没有涉及，判决书回避了重要的问题。</p><p>你会发现，它最终支持郭兵的就是那剩下的1300多块钱，如果他因为动物园这种单方面入园方式变更而进不了园，实际上动物园本来就应该返还给他这个钱。这样的判决给其他的企业传递了什么信息呢？——我尽管收集好了，如果有一些民众想要反抗，他如果愿意跟我打官司，反正我赔偿的也就是千儿八百块钱。这个判决不就在变相鼓励别的企业都去收集人脸数据吗？</p><p>它没有产生我们预期的那种效果。雷声大，最终雨点小。</p><p><img src="https://chinadigitaltimes.net/chinese/files/2020/12/post-660513-5fd85330d7137." alt="图片" class="aligncenter" width="500"></p><p><em>第二届数字中国建设成果展览会，观众在展览会上体验人脸识别技术</em></p><p><strong>《人物》：12月2日表决通过的《天津市社会信用条例》提到：「市场信用信息提供单位不得采集自然人的宗教信仰、血型、疾病和病史、生物识别信息以及法律、行政法规规定禁止采集的其他个人信息」，网络评价称，这是全国首个公开禁止采集人脸识别信息的法规。你怎么看待这件事的意义？</strong></p><p>劳东燕：在我看来，这个规定虽然有一定意义，但可能意义没有大家预估的那么大。这个条例涉及的范围还是比较窄的，它涉及到的应该是关于社会信用信息的收集主体，主要还是公共管理部门。它不一定能管到动物园、小区这些和普通人更息息相关的机构。一般而言，比如最近南京禁止售楼处使用人脸识别，售楼处这些商业机构一般不涉及社会公共信用的问题，所以这种条例应该也不会涉及。在我看来，杭州最近公布的《物业管理条例（草案）》可能意义更大，因为物业会涉及到更多普通人的日常信息。社会信用方面的收集，本身收集的机构可能就少。另外，物业作为收集主体，数据安全方面的风险，无论是泄露还是滥用，风险会更大。</p><p>不过，这两个条例都是地方监管部门在上位法所传递的导向下所做的局部探索，应该说是很好的尝试。</p><p><strong>《人物》：为什么天津会率先有这样的条例呢？</strong></p><p>劳东燕：不同地方的监管部门对人脸识别会有不同认识。去年下半年以来，一些部门的内部，对于个人信息方面的问题了解得更为全面以后，可能更知道其中的风险。据我所知，在浙江，至少在公安系统内部，其实就不再要求宾馆一定要通过人脸识别认证住户信息，也可以通过身份证去认证。现在浙江有的宾馆还在继续，但顾客是有权拒绝的。此外，地方政府内部的不同部门可能在这上面会有不同的考量。比如说杭州的《物业管理条例（草案）》，我知道司法局做了很大的努力。据我了解到的情况，这个草案推动人脸识别相关规定时，是遇到较大阻力的，有其他部门并不愿意，因为一旦人脸识别要加以规制，他们的执法压力可能会大很多。很多时候，在立法上——包括地方性立法或者中央性立法，部门性的利益都是很关键的。如果有一种呼声特别大或者特别强势，可能就会影响最后的决策。我们媒体现在看到的杭州、天津、南京的变化，还是少数城市区域性的尝试，大部分地方的监管部门还没有做出明确的反应。</p><p><strong>《人物》：人脸识别技术的推广者往往会用「便利」、「安全」的说法，你怎么看待这点？</strong></p><p>劳东燕：他们所说的「便利」对我没有诱惑力。我并不觉得自己的几秒、十几秒时间如此地有价值。但在人脸识别推广中，说服大家接受时，用得最多的就是这个理由。在人脸识别这项技术的推广中，最大的受益方肯定不是民众，普通民众更可能是「冤大头」的角色。</p><p>从「安全」角度来讲也有明显的问题。为了控制罪犯，把所有人的生物信息都收集走，收集后的保管与使用环节又无法保证基本的安全。这样一来，我们的信息被泄露、被滥用，就是我们的安全受到了威胁。「公共」不是虚的概念，我们每个人都是公众中的一员。</p><p><strong>《人物》：李彦宏说过中国人愿意「用隐私换便捷」，你认同这一点吗？</strong></p><p><strong>劳东燕：</strong>我不认同。我觉得，根本的原因，是因为信息披露得不充分不完整，相应风险被告知得不够，让大家误以为其中只有好处而没有风险或风险很小。你只要告知相应的风险，人们不见得就一定喜欢用隐私换安全换便利。我往两个小区群里发文章，没一个业主出面反对，反而有很多赞成的。只要如实地披露其中的风险，人们马上就会意识到，不应该用隐私换便捷，这很可能是在与魔鬼做交易。人在所接受的信息不充分不完整的情况下，可能会更注重眼前利益，那是因为你没有告诉他其中的风险所在，以及这个事情可能会往什么方向发展。</p><p><strong>《人物》：是不是这种风险也有隐蔽性、滞后性，所以人们很难真切地感受、强烈地重视。</strong></p><p><strong>劳东燕：</strong>对，从人脸信息被买卖、泄露到发生风险往往会有一段时间。但你想，有人买你的人脸数据，如果无利可图，他怎么会买呢？再往前想几步，你的人脸信息掌握在一个想用来谋利的人手里，就等于有雷埋在那里，只是你不知道这个雷什么时候会爆炸。</p><p><strong>《人物》：你在学术论坛上说，自己向小区抗议人脸识别门禁，只是「挣扎了一下」。你怎么看待这样的挣扎？</strong></p><p><strong>劳东燕：</strong>有的时候，你会发现挣扎一下是有用的。</p><p>在小区这样的场景中，由于物业没有内在动力去推行，如果有反对声告诉他存在的法律风险，可能就退让了。这也是在一些小区人脸识别没有继续推行下去的原因。其他场景中，挣扎可能就不管用，比如在宾馆抗争使用人脸识别，宾馆会拒绝让你居住。挣扎有时需要付出代价，也受到很多现实的制约。日常生活里，我会告诉我的孩子不要贪小便宜而使用某些技术，也会尽量避免在使用APP时录入我的人脸信息。</p><p><strong>《人物》：普通人能做什么？</strong></p><p><strong>劳东燕：</strong>发出自己的声音，以使在舆论和社会当中形成合力。这种合力有助于抵制人脸识别技术的滥用，且可能会改变立法与相应的决策。这是我认为当下每个公民都可以做的。</p><p>做技术的人总会说技术中性，他们很少思考技术与社会的关系问题，也不关注社会系统如何运作。技术是在现实社会空间中运行的，影响也会波及到现实社会，怎么可能是中性的？其实我们每个人都困在系统里，被控制在算法里，差别只在于程度的不同。对于科技企业决策者、官员而言，他们也是系统中的一部分，也有作为普通人的一面。技术具有不确定性和反噬效应，你如果想控制别人，别人也可能反过来控制你。所以，他们也会面临个人生物信息被泄露与滥用的风险。</p><p>我曾和产业界的人一起参会，一名科技公司的管理人员提到，公司内部讨论产品是否要推广于教育场景时，她提出了反对——在那个时刻，她既是科技领域的企业管理者，也是一位母亲。现在没有遭遇危机，不代表着永远不会。现在一些小区，对租户实行人脸识别门禁，业主则可以自由选择。很多做法的推行都会利用人们的这种心理，在把少数人排除出去侵害他们的权利的同时，通过承诺保障多数人的利益，借此来争取多数人的同意，从而让侵害少数人权利的做法变得可接受。我非常反对这种做法。我们经常觉得，别人的权利被侵害了没有关系，只要不侵害自己的就可以。但你会发现，下一次你随时有可能成为少数人，到那时，你的权利被侵害，自然也没有人站出来为你说话。</p><p><strong>《人物》：在现代社会，个人信息为什么会如此重要？</strong></p><p><strong>劳东燕：</strong>个人信息是否值得保护，不取决于这个信息是否涉及隐私，而取决于通过这个信息能否识别到你。如果可以通过某个信息或结合其他信息识别到特定的自然人，这样的信息就是法律要加以保护的。这次《民法典》也在隐私权之外，额外地规定了个人信息权利。匿名性是现代社会运作的基础。你并不想所有举动都被毫无遗漏地永久记载下来，曝光在每一个人的面前。不然，你可能发现，在任何地方，都可能有一只眼睛始终在盯着你。你因此丧失了自由，并且也不见得会拥有安全感。<img src="https://mmbiz.qpic.cn/mmbiz_jpg/DezXb6Zd7Shq7TDAfMSnNEwCoKWGQa9tJfWgqEJO197icZ6HYA5NTbWJrlTj0XUOxnMgrAFQ69rF313iaTBU1dDA/640?wx_fmt=jpeg&amp;amp;tp=webp&amp;amp;wxfrom=5&amp;amp;wx_lazy=1&amp;amp;wx_co=1" alt="图片"></p><p><img src="https://chinadigitaltimes.net/chinese/files/2020/12/post-660513-5fd85334ad16b." alt="图片" class="aligncenter" width="500"></p>
